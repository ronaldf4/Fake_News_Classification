{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://100percentfedup.com/category/politics/page/1/\n",
      "17 17 17\n",
      "https://100percentfedup.com/category/politics/page/2/\n",
      "37 37 37\n",
      "https://100percentfedup.com/category/politics/page/3/\n",
      "49 49 49\n",
      "https://100percentfedup.com/category/politics/page/4/\n",
      "63 63 63\n",
      "https://100percentfedup.com/category/politics/page/5/\n",
      "77 77 77\n",
      "https://100percentfedup.com/category/politics/page/6/\n",
      "93 93 93\n",
      "https://100percentfedup.com/category/politics/page/7/\n",
      "105 105 105\n",
      "https://100percentfedup.com/category/politics/page/8/\n",
      "121 121 121\n",
      "https://100percentfedup.com/category/politics/page/9/\n",
      "133 133 133\n",
      "https://100percentfedup.com/category/politics/page/10/\n",
      "150 150 150\n",
      "https://100percentfedup.com/category/politics/page/11/\n",
      "166 166 166\n",
      "https://100percentfedup.com/category/politics/page/12/\n",
      "186 186 186\n",
      "https://100percentfedup.com/category/politics/page/13/\n",
      "211 211 211\n",
      "https://100percentfedup.com/category/politics/page/14/\n",
      "235 235 235\n",
      "https://100percentfedup.com/category/politics/page/15/\n",
      "256 256 256\n",
      "https://100percentfedup.com/category/politics/page/16/\n",
      "269 269 269\n",
      "https://100percentfedup.com/category/politics/page/17/\n",
      "288 288 288\n",
      "https://100percentfedup.com/category/politics/page/18/\n",
      "299 299 299\n",
      "https://100percentfedup.com/category/politics/page/19/\n",
      "309 309 309\n",
      "https://100percentfedup.com/category/politics/page/20/\n",
      "325 325 325\n",
      "https://100percentfedup.com/category/politics/page/21/\n",
      "336 336 336\n",
      "https://100percentfedup.com/category/politics/page/22/\n",
      "356 356 356\n",
      "https://100percentfedup.com/category/politics/page/23/\n",
      "374 374 374\n",
      "https://100percentfedup.com/category/politics/page/24/\n",
      "388 388 388\n",
      "https://100percentfedup.com/category/politics/page/25/\n",
      "405 405 405\n",
      "https://100percentfedup.com/category/politics/page/26/\n",
      "426 426 426\n",
      "https://100percentfedup.com/category/politics/page/27/\n",
      "442 442 442\n",
      "https://100percentfedup.com/category/politics/page/28/\n",
      "464 464 464\n",
      "https://100percentfedup.com/category/politics/page/29/\n",
      "484 484 484\n",
      "https://100percentfedup.com/category/politics/page/30/\n",
      "494 494 494\n",
      "https://100percentfedup.com/category/politics/page/31/\n",
      "506 506 506\n",
      "https://100percentfedup.com/category/politics/page/32/\n",
      "514 514 514\n",
      "https://100percentfedup.com/category/politics/page/33/\n",
      "528 528 528\n",
      "https://100percentfedup.com/category/politics/page/34/\n",
      "547 547 547\n",
      "https://100percentfedup.com/category/politics/page/35/\n",
      "563 563 563\n",
      "https://100percentfedup.com/category/politics/page/36/\n",
      "584 584 584\n",
      "https://100percentfedup.com/category/politics/page/37/\n",
      "606 606 606\n",
      "https://100percentfedup.com/category/politics/page/38/\n",
      "622 622 622\n",
      "https://100percentfedup.com/category/politics/page/39/\n",
      "640 640 640\n",
      "https://100percentfedup.com/category/politics/page/40/\n",
      "656 656 656\n",
      "https://100percentfedup.com/category/politics/page/41/\n",
      "673 673 673\n",
      "https://100percentfedup.com/category/politics/page/42/\n",
      "688 688 688\n",
      "https://100percentfedup.com/category/politics/page/43/\n",
      "699 699 699\n",
      "https://100percentfedup.com/category/politics/page/44/\n",
      "713 713 713\n",
      "https://100percentfedup.com/category/politics/page/45/\n",
      "729 729 729\n",
      "https://100percentfedup.com/category/politics/page/46/\n",
      "745 745 745\n",
      "https://100percentfedup.com/category/politics/page/47/\n",
      "759 759 759\n",
      "https://100percentfedup.com/category/politics/page/48/\n",
      "772 772 772\n",
      "https://100percentfedup.com/category/politics/page/49/\n",
      "788 788 788\n",
      "https://100percentfedup.com/category/politics/page/50/\n",
      "805 805 805\n",
      "https://100percentfedup.com/category/politics/page/51/\n",
      "821 821 821\n",
      "https://100percentfedup.com/category/politics/page/52/\n",
      "838 838 838\n",
      "https://100percentfedup.com/category/politics/page/53/\n",
      "855 855 855\n",
      "https://100percentfedup.com/category/politics/page/54/\n",
      "876 876 876\n",
      "https://100percentfedup.com/category/politics/page/55/\n",
      "893 893 893\n",
      "https://100percentfedup.com/category/politics/page/56/\n",
      "908 908 908\n",
      "https://100percentfedup.com/category/politics/page/57/\n",
      "929 929 929\n",
      "https://100percentfedup.com/category/politics/page/58/\n",
      "946 946 946\n",
      "https://100percentfedup.com/category/politics/page/59/\n",
      "958 958 958\n",
      "https://100percentfedup.com/category/politics/page/60/\n",
      "974 974 974\n",
      "https://100percentfedup.com/category/politics/page/61/\n",
      "986 986 986\n",
      "https://100percentfedup.com/category/politics/page/62/\n",
      "998 998 998\n",
      "https://100percentfedup.com/category/politics/page/63/\n",
      "1014 1014 1014\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "#Initializing in order to scrape website as agent not as crawler\n",
    "headers = {\n",
    "    'User-Agent': 'My User Agent 1.0'\n",
    "}\n",
    "\n",
    "#Start with first page\n",
    "page = 1\n",
    "\n",
    "#Initializing\n",
    "final_title_list = []\n",
    "body_list = []\n",
    "date_list = []\n",
    "title_list = None\n",
    "p_list = []\n",
    "\n",
    "#Generic ULR of website\n",
    "link = \"https://100percentfedup.com/\"\n",
    "\n",
    "#Loop to get approx 1000 news articles according to length of the body list\n",
    "while len(body_list) <= 1000: \n",
    "    \n",
    "    #Modified URL in order to navigate to next page\n",
    "    add = \"page/\"+str(page)+\"/\"\n",
    "    \n",
    "    #Generic Url to get fake news\n",
    "    url = link + \"category/politics/\" + add\n",
    "    \n",
    "    print(url)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code==200:  \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')  \n",
    "\n",
    "        #Scrapping All the titles first\n",
    "        titles = []\n",
    "        title_list = soup.select('div.wpdev-post-grid-item h2')\n",
    "        for idx,t in enumerate(title_list):\n",
    "            titles.append(t.text)\n",
    "\n",
    "        #Scrapping date and body of fake news using previously scrapped titles\n",
    "        for t in titles:\n",
    "            \n",
    "            #Some preprocsessig in order to get the URL of pertiicular article\n",
    "            tokens = re.split(r'\\W+', t.lower().replace(r\"…“”’‘\",\"\"))\n",
    "            click = \"-\".join(tokens)\n",
    "            new_url = link + click + \"/\"\n",
    "            \n",
    "            #Hitting every title's URL in order to extract content (body) and date of the article\n",
    "            response = requests.get(new_url, headers=headers)\n",
    "            if response.status_code==200:  \n",
    "                soup = BeautifulSoup(response.content, 'html.parser') \n",
    "\n",
    "                #Extracting the date\n",
    "                date = []\n",
    "                date = soup.select(\"h4\")                   \n",
    "\n",
    "                #Extracting the body paragraphs\n",
    "                body = \"\"\n",
    "                p_list = soup.select(\"div.entry-content p\")\n",
    "                \n",
    "                #Scraping only text hence p_list[1:] since first element is not simple body of text\n",
    "                for p in p_list[1:]:\n",
    "                    if len(p.text) > 0:\n",
    "                        body = body + p.text\n",
    "                                                  \n",
    "                #Appending to global list only when body is found\n",
    "                if(len(body) > 0):\n",
    "                    body_list.append(body)\n",
    "                    final_title_list.append(t)\n",
    "                    date_list.append(date[0].get_text())\n",
    "                    \n",
    "    print(len(body_list),len(final_title_list),len(date_list))\n",
    "    \n",
    "    #Going to next page\n",
    "    page = page + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 2 dataset from the scrapped data \n",
    "i = 0\n",
    "data_title = []\n",
    "data_body = []\n",
    "while i < len(body_list):\n",
    "    data_title.append((date_list[i],final_title_list[i],'fake'))\n",
    "    data_body.append((date_list[i],body_list[i],'fake'))\n",
    "    i = i + 1\n",
    "df_only_statement = pd.DataFrame(data_title, columns=['date', 'statement', 'label'])\n",
    "df_only_body = pd.DataFrame(data_body, columns=['date', 'body', 'label'])\n",
    "\n",
    "#to get csv\n",
    "df_only_statement.to_csv('1000_fake_only_statement.csv')\n",
    "df_only_body.to_csv('1000_fake_only_body.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
